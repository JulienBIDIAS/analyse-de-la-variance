---
output:
  pdf_document:
    number_sections: yes
    fig_caption: yes
  word_document: default
  html_document:
    df_print: paged
outp ut:
  pdf_document:
    toc: no
    fig_caption: yes
    number_sections: yes
header-includes: 
  - \usepackage{pdfpages}
  - \usepackage{tcolorbox}
  - \usepackage{graphicx}
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
library(tidyr)
library(tidyverse)
library(dplyr)
library(knitr)
library(lattice)
library(rgl)
library(ggforce)
library(ks)
library(esquisse)
library(datarium)
library(psych)
library(readxl)
library(lmtest) #Pour le test d'homosecedasticité
library(afex)
library(ggpubr)
library(rstatix)
library(lme4)
library(car)
library(MASS)
knitr::opts_chunk$set(echo = FALSE)
```

```{=tex}
\includepdf{page}
\newpage
\begin{tcolorbox}[colback=white,colframe=blue,title=Avant-propos]
Ce travail a été réalisé dans le cadre de la validation du \textbf{cours d'ANOVA sur mesures repétées}. L'objectif principal de celui-ci était de mettre en pratique les méthodes d'analyses économétriques entre variables qualitatives et variables quantitatives apprises au cours d'Analyse de la variance. Mais pour le cas d'espèce il s'agit particulièrement de l'analyse de la variance à mesures répétées.\\

Le jeu de données utilisé pour cette analyse était constitué de 253 observations. L'analyse a permis de mettre en évidence des effets similaires entre les groupes (modalité de chaque facteur) avec une p valeur supérieur à 0,05.\\

Le présent rapport est structuré en plusieurs sections, commençant par un rappel sur la théorie de l'analyse de la variance à mesures repétées, enchainant ensuite avec la présentation des données, les analyses descriptives et enfin la modélisation suivit de la présentation des résultats et leur interprétation.

\end{tcolorbox}
```
```{=tex}
\newpage
\renewcommand{\contentsname}{\textcolor{blue}{Table des matières}}
```
\textcolor{blue}{\tableofcontents}

```{=tex}
\newpage
\renewcommand{\listfigurename}{\textcolor{blue}{Liste des figures}}
\textcolor{blue}{\listoffigures}
```
```{=tex}
\newpage
\renewcommand{\listtablename}{\textcolor{blue}{Liste des tableaux}}
\textcolor{blue}{\listoftables}
```
\newpage

```{=tex}
\begin{tcolorbox}[colback=white,colframe=blue,title=Contexte d'application et objectif]
L'analyse de variance (ANOVA) à deux facteurs à mesures répétées avec interaction est une méthode statistique utilisée pour analyser les données issues d'une expérience avec au moins deux variables indépendantes (facteurs) et une variable dépendante mesurée à plusieurs reprises (d'où les termes : mesures repétées). L'objectif étant d'étudier l'interaction entre ces deux facteurs ceci afin d'analyser l'influence conjointe des facteurs sur la variable dépendante.\\

En effet, les mesures sont répétées pour chaque combinaison des niveaux des deux facteurs. L'idée de \textbf{répétition} étant mise en exergue pour inférer sur les effets des facteurs et leur interaction car elles permettent de contrôler les sources de variation entre les  sujets considérés. D'autre part, l'interaction signifie que l'effet d'un facteur dépend de la valeur de l'autre facteur. Laquelle interaction sera siginificative lorsque les effets des deux facteurs ne seront pas constants dans toutes les combinaisons des niveaux des facteurs. L'anova à mesures répetées cherche donc à répondre à la question de savoir quelle est l'influence des facteurs (qualitatifs) sur une variable (quantitative) comptenu des mesures de cette dernière sur différentes périodes ? 

Il existe donc à cet effet une pléthore de méthodes d'ajustement pour efffectuer de l'Anova à plusieurs facteurs à mesures répétées avec ou sans interaction. On distingue : 

\textbf{Les méthodes de type Greenhouse-Geisser}, qui permettent de corriger les estimations des degrés de liberté et de F-tests en cas de non-sphéricité des données ; 

\textbf{Les méthodes de type Huynh-Feldt} sont également couramment utilisées pour corriger les estimations des degrés de liberté et de F-tests.
\end{tcolorbox}
```
\newpage

\textcolor{blue}{\section{Théorie sur l'Analyse de la variance à mesures repétées}}

Nous allons dès à présent expliquer succintement l'anova à mesures
repétée en partant de la présentation des données, de l'écriture du
modèle,les hypothèses de base et enfin nous présenterons l'inférence du
modèle via le tableau d'analyse de la variance.

\textcolor{blue}{\subsection{Présentation des données}}

Pour mieux comprendre l'Anova à mesures repétées, il convient de
préciser que celle-ci peut se faire dans un plan équilibré comme dans un
plan déséquilibré. De manière générale, toute expérimentation comportant
au moins un facteur et comportant un nombre identique de répétitions
dans chacune des modalités des facteurs est un plan équilibré. Dans le
cas contraire, on parle d'un plan **déséquilibré**. Nous présenterons
succintement l'anlayse de la variance à deux facteurs à mesures
répétées. Laquelle permettra selon la décision du test de prolonger sur
l'analyse de la variance à un facteur à mesures répétées en cas
d'absence d'interaction ou à faire des comparaisons par paires dans le
cas contraire.

\textcolor{blue}{\subsection{Plan équilibré}}

Nous allons nous placer dans le cadre de l'anova à deux facteurs à
mesures repétées avec des effets fixes. le cas des effets aléatoires se
déduisant facilement car pour ce dernier il suffit juste de considérer
que les facteurs sont des variables aléatoires suivant une loi nromale.
Nous palerons brièvement du cas des facteurs emboîtés.

Considérons donc le tableau ci-dessous

```{=tex}
\begin{table}[!h]
\centering
\caption{Données}
\includegraphics[width=10cm]{t1.png}
\end{table}
```
Pour lequel nous postulons le modèle suivant :

$$Y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha \beta)_{ij} + \varepsilon_{ijk}$$
Avec $i = 1, 2, ..., I$ le nombre de modalités du facteur $\alpha$,
$j = 1, 2, ..., J$ le nombre de modalités du facteur $\beta$ et
$k = 1, 2, ..., K$ le nombre de périodes ou nombre de répétitions. Où
$Y_{ijk}$ est la valeur prise par la réponse $Y$ dans les conditions
$(A_i,B_j)$ lors du $k^{ème}$ essai. $\mu$ désigne le facteur commun,
$\alpha$ le premier facteur pour $I$ modalités, $\beta$ le second
facteur pour $J$ modalités et $\varepsilon$ est l'erreur. Tel que
susmentionné, nous voulons étudier l'intéraction entre les facteurs afin
de voir leur effet sur la variable $Y$.

Pour ce faire, nous partons donc des hypothèses de l'anova :
$\forall (i,j,k)$ $1\leq i \leq I$, $1\leq j \leq J$, $1\leq k \leq K$
$\mathcal{L} (\varepsilon_{ijk}) = \mathcal{N} (0, \sigma^2)$, et
$cov(\varepsilon_{ijk}, \varepsilon_{lmn}) = 0$ si $ijk \ne lmn$ avec
$1\leq i, l \leq I$, $1\leq j,m \leq J$ et $1\leq k,n \leq K$. Nous
supposerons qu'elles sont bien remplies pour la suite. Par ailleurs,
certaines métriques utilisées pour résoudre notre modèle dans la
pratique sont robustes. Ce qui fait souvent que nous puissions grâce aux
logiciels ajuster nos modèles. A ces hypohtèses, l'on pourrait ajouter
celles de normalité sur les $\alpha_i$ et les $\beta_j$ et dans ce cas
l'on parlera d'un modèle d'anova à deux facteurs à effets aléatoires.

Par ailleurs, la notion d'analye de la variance à mesures répétées à
facteurs emboîtés quant-à-elle fait référence au cas où les modalités
d'un facteur dépend des modalités de l'autre facteur.

Les contraintes suivantes sont étabies pour pour pouvoir estimer les
paramètres du modèle et passer à la décomposition de la variance.

$\sum_{i=1}^I \alpha_i =0$, $\sum_{j=1}^J \beta_i =0$,
$\sum_{i=1}^I (\alpha \beta)_{ij}=0$ $\forall j \in \{1,...,J\}$ et
$\sum_{j=1}^J (\alpha \beta)_{ij}=0$ $\forall i \in \{1,...,I\}$.

Les estimateurs $\mu$, $\alpha_1$, ..., $\alpha_I$, $\beta_1$, ...,
$\beta_J$ des paramètres $\mu$, $\alpha_1$, ..., $\alpha_I$, $\beta_1$,
..., $\beta_J$ sont donnés par les formules suivantes :

$\hat{\mu} = \bar{Y}$, $\hat{\alpha_i} = Y_i. - \hat{\mu}$
$1\leq i \leq I$, $\hat{\beta_j} = Y_.j - \hat{\mu}$, $1 \leq j \leq J$.

Ainsi, nous donnons le tableau suivant qui est celui des réalisations de
Y.

```{=tex}
\begin{table}[!h]
\centering
\caption{Données}
\includegraphics[width=10cm]{t2.png}
\end{table}
```
La décomposition de la variance se fait donc ainsi qu'il suit :

$$sc_{TOT} = sc_{A} + sc_{B} + sc_{AB} + sc_{R}$$ La variation due au
facteur A observée sur la liste de données y est définie par :

$$sc_{A} = JK \sum_{i=1}^I (y_{i..}-y_{...})^2$$

La variation due au facteur B observée sur la liste de données y est
définie par :

$$sc_{B} = IK \sum_{j=1}^J (y_{.j.}-y_{...})^2$$

La variation due à l'interaction des facteurs A et B observée est :

$$sc_{AB} = K \sum_{j=1}^J \sum_{i=1}^I (y_{ij.}-y_{i..}-y_{.j.}+y_{...})^2$$

La variation résiduelle observée sur la liste de données y est définie
par :

$$sc_R =\sum_{j=1}^J \sum_{i=1}^I \sum_{k=1}^K (y_{ijk} - y_{ij.})^2$$

\newpage

La relation fondamentale de l'ANOVA reste valable lorsqu'elle est
évaluée sur la liste de données y. Nous introduisons les degrés de
liberté (Ddl) associés à chaque ligne du tableau de l'ANOVA :

```{=tex}
\begin{table}[!h]
\centering
\caption{Degrés de liberté}
\includegraphics[width = 10cm]{t4.png}
\end{table}
```
D'où le tableau d'analyse de la variance suivant :

```{=tex}
\begin{table}[!h]
\centering
\caption{Tableau d'analyse de la variance-Rappel}
\includegraphics[width = 10cm]{t3.png}
\end{table}
```
Nous souhaitons faire les tests d'hypothèses suivant :

\textcolor{blue}{Test d'hypothèse sur le premier facteur}

$H_{0}$: $\alpha_{1}= \alpha_{2}= \alpha_{3}=...= \alpha_{I}=0$ contre
l'hypothèse

$H_{1}$: il existe $i_{0}$ appartenant à ${1,2,3,...,I}$ tel que
$\alpha_{i_{0}} \ne 0$

Sous l'hypothèse nulle ($H_{0}$) représente l'absence d'effet du facteur
$\alpha$ et lorsque les conditions de validité du modèle sont
respectées, $F_{(\alpha ,obs)}$ est la réalisation d'une variable
aléatoire qui suit une loi de Fisher à $I-1$ degrés de liberté. Si la
valeur de la statistique calculée est supérieure à la valeur tabulée
alors on accepte l'hypothèse nulle d'absence d'effet de groupe des
modalités du facteur sur l'explication de la variable dépendante.

\textcolor{blue}{Test d'hypothèse sur le second facteur}

$H_{0}$: $\beta_{1}= \beta_{2}= \beta_{3}=...= \beta_{J}=0$ contre
l'hypothèse

$H_{1}$: il existe $j_{0}$ appartenant à ${1,2,3,...,J}$ tel que
$\beta_{i_{0}} \ne 0$

L'hypothèse nulle ($H_{0}$) représente l'absence d'effet du facteur
$\beta$ et lorsque les conditions de validité du modèle sont respectées,
$F_{\beta, obs}$ est la réalisation d'une variable aléatoire qui suit
une loi de Fisher à $(J-1)$ degré de liberté. On conclut comme
précedemment.

Pour l'intéraction nous avons :

$H_{0}$:
$(\alpha \beta)_{11} = (\alpha \beta)_{12}=...=(\alpha \beta)_{ij}=0$

$H_{1}$: il existe $i_{0}$,$j_{0}$ tel que
$(\alpha \beta)_{i_{0}j_{0}} \ne 0$

Sous l'hypothèse nulle $H_{0}$ représente l'absence d'effet du facteur
et lorsque les conditions de validité du modèle sont respectées,
$F_{(\alpha \beta),obs}$ est la réalisation d'une variable aléatoire qui
suit une loi de Fisher à $(I-1)(J-1)$ degré de liberté. Si la
statistique calculée de Fisher est supérieure à la valeur tabulée alors
on acceptera l'hypothése nulle d'absence d'effet de groupe des modalités
d'un facteur croisé avec d'autres. C'est-à-dire que les facteurs ont les
mêmes effets pris ensemble.

\newpage

\textcolor{blue}{\section{Présentation du problème, des données et analyse descriptive des différentes variables}}

\textcolor{blue}{\subsection{Présentation du problème}}

Nous voulons étudier l'influence de deux facteurs que sont : **le
fertilisant et la variété de fruits** sur la croissance des plantes.
Pour cela, nous disposons du jeu de données suivant ayant en colonne le
Numéro, les répétitions (Identifacteur), le temps("time"), le
fertilisant qui a trois modalités qui sont en fait les trois types de
terreau qui ont été utilisés :

```{=tex}
\begin{itemize}
\item Terreau de Manguier (Ma)
\item Terreau de Caïlcédrat (Ca)
\item Terreau d’Anacarde (An)
\end{itemize}
```
La variété de fruit qui a deux modalités :

```{=tex}
\begin{itemize}
\item Variété1 (Dg)
\item Variété2 (Ds)
\end{itemize}
```
Les plantes ayant été mesurées à quatre périodes (4 répétitions de
mesure). L'objectif étant de voir s'il existe une combinaison ou un
traitement (type de terreau X variété) qui favorise la croissance ou non
des plantes.

\textcolor{blue}{\subsection{Présentation des données et méthodologie}}

C-dessous la base.

```{r, echo=FALSE}

datas = read_excel("001.BASE TP ANOVA 2022-2023.xlsx")
table = kable(head(datas, 5), caption = 'Base partielle-Début')
table
```

**Affichage des 5 dernières lignes**

```{r, echo=FALSE}
table1 = kable(tail(datas, 5), caption = 'Base partielle-Fin')
table1


```

Pour apporter des éclairages à notre problème, nous allons effectuer une
analyse de la variance à deux facteurs à mesures répétées.

Le modèle s'écrit donc comme suit :

$$Y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha \beta)_{ij} + \varepsilon_{ijk}$$
Où $\mu$ représente l'effet commun des différents facteurs ;

$\alpha_i$ représente le facteur associé au fertilisant. Avec $i$ la
ième modalité de ce dernier (Ma, Ca, An). On a $i = 1,...,I$ avec $I$ le
nombre de modalités. $I=3$ ;

$\beta_j$ représente le facteur associé à la variété. Avec $j$ la jème
modalité (Ds,Dg). on a $j = 1,...,J$ avec $J=2$ le nombre de modalités ;

$(\alpha \beta)_{ij}$ est l'interaction entre les modalités des deux
facteurs que sont le fertilisant et la variété.

$k$ étant le nombre de répétitions. $k =1,..., K(i,j)$. avec \$ K(i,j) =
4\$

$Y_{ijk}$ est la hauteur de la plante pour différentes périodes et ce
pour chaque modalité des deux facteurs.

$\varepsilon_{ijk}$ représente l'erreur pour différentes périodes et ce
pour chaque modalité des deux facteurs. Elle capte tout ce que la partie
deterministe du modèle $\mu + \alpha_i + \beta_j + (\alpha \beta)_{ij}$
ne peut expliquer.

Enfin nous postulons le modèle général avec intéraction. Mais pour mieux
le comprendre nous partirons du modèle avec un facteur à mesures
répétées et ensuite à deux facteurs à mesures repétées avec interaction.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
datas$Repetition = as.factor(datas$Repetition)
datas$Fertilisation = as.factor(datas$Fertilisation)
datas$Varietes = as.factor(datas$Varietes)
datas$Time = as.factor(datas$Time)
```

\textcolor{blue}{\textbf{Informations sur la base de données}}

```{r, echo=FALSE, warning=FALSE, message=FALSE}
print(str(datas))
```

Les variables Répetition, Time, Fertisation et Varietes sont de type
facteur. La Hauteur ici notre variable dépendante est de type numérique.
Ce qui semble correct car elle est par nature quantitative. Nous avons
donc 253 lignes pour 6 colonnes. En effet nous sommes dans **un plan
déséquilibré** compte tenu du fait que pour différentes mesures nous
n'avons pas les mêmes nombre d'individus suivant les modalités des
facteurs.

\textcolor{blue}{\subsection{Analyse descriptive}}

Elle sera basée sur la hauteur moyenne des plantes pour chaque modalité
du facteur considéré afin de voir numeriquement comment celles-ci sont
réparties. Ensuite, nous ferons des représentations graphiques pour
apprécier ces résultats généraux. Nous ferons donc aussi des box-plots.

\textcolor{blue}{\textbf{Tendances centrales}}

```{r, echo=FALSE}
datas_Means.Table = describe(datas)

knitr::kable(datas_Means.Table, digits = 2, caption = 'Tendances centrales')
```

Pour mieux apprécier celles-ci nous ferons des moyennes regroupées :

```{r}
Moyenne_Fertilisant = tapply(datas$Hauteur, c(datas$Fertilisation), mean)
kable(Moyenne_Fertilisant, caption = "Hauteur Moyenne pour chaque fertilisant pour différentes mesures")
```

```{r}
Moyenne_variete = tapply(datas$Hauteur, datas$Varietes, mean)
kable(Moyenne_variete, caption = "Hauteur Moyenne pour chaque variété pour différentes mesures")

```

D'après ces deux tableaux, on peut dire que prit sans intéraction,
c'est-à-dire au sein de chaque groupe on voit que les hauteurs moyennes
pour chaque modalité des facteurs sont très proches. Comme pour dire que
les différents types d'engrais ont des effets similaires sur la
croissance des plantes ou les types de variétés aussi. On ne peut dire
indépendamment des facteurs. Mais cela reste valable du point de vue des
moyennes. Toutefois, nous confimerons cela à l'étape de la modélisation.

Donnons dès à présent le tableau des moyennes croisées de chaque facteur
:

```{r}
croisement = datas |> 
  group_by(Fertilisation, Varietes) |> 
  get_summary_stats(Hauteur, type = "mean_sd")
kable(croisement, caption = "Hauteur moyenne pour chaque modalité des facteurs")
```

A la lecteur de ce tableau, quand on prend la colonne des moyennes, on
peut faire le même constat que précédemment. Aussi, la colonne des
tailles d'échantillon montre bien que le plan est déséquilibré. Par
ailleurs, quand on prend la combianaison (Ca, Dg) on voit que la moyenne
est de 38,2. Ce qui semble légèrement supérieur aux autres couples. On
pourrait penser à un effet de groupe. Toutefois, par le biais des tests
nous pourrons vérifer cela. On peut aussi donner la moyenne des hauteurs
moyennes et la médiane aussi.

```{r}
print(c(mean(croisement$mean), median(croisement$mean)))
```

Elles sont presque identique. Il y a une présomption de symétrie de la
distribution des Haueteurs moeynnes des plantes suivant chaque modalité
des facteurs prit deux à deux. D'où l'idée encore d'une potientelle
présence d'effets similaires des facteurs sur la variable dépendante. On
peut apprécier tout ceci via des graphques croisés. Aussi des graphiques
indépendants.

**Visualisation graphique du croisement**

```{r, fig.cap="Hauteur myenne des plantes suivant le fertilisant et pour chaque variete", fig.dim=c(4,2.5)}
ggplot(croisement) +
  aes(x = Fertilisation, y = mean, fill = Varietes) +
  geom_col() +
  scale_fill_hue(direction = 1) +
  theme_minimal()
```

\newpage

\textcolor{blue}{\textbf{Visualisation de la taille des plantes en fonction du type d'engrais}}

```{r, echo=FALSE, fig.cap="Taille moyenne des pantes en fonction de chaque fertilisant", fig.dim=c(4,2.5)}

ggplot(croisement) +
 aes(x = Fertilisation, y = mean, fill = Fertilisation) +
 geom_col() +
 scale_fill_manual(values = c(An = "#E76259", 
Ca = "#00C19F", Ma = "#9292F4")) +
 theme_minimal()

```

A ce niveau, le constat semble pareil de part l'observation de ce
graphique.

\textcolor{blue}{\textbf{Visualisation de la taille des plantes en fonction des variétés de fruits}}

```{r, echo=FALSE, fig.cap="Taille des plantes en fonction des variétés de fruits", fig.dim=c(4,2.5)}

ggplot(croisement) +
  aes(x = Varietes, y = mean, fill = Varietes) +
  geom_col() +
  scale_fill_brewer(palette = "Set1", direction = 1) +
  theme_minimal()
```

Jusqu'ici les constats restent valable. A noter qu'il s'agit juste de
constat. Lesquels seront infirmés ou confirmés plus bas.

\newpage

\textcolor{blue}{\textbf{Box-plot}}

Commençons par les box-plots de la hauteur moyenne suivant les
différentes périodes :

```{r, echo=FALSE, fig.cap="Box Plot de la hauteur pour chaque période", fig.dim=c(4,2.5)}
ggplot(data = datas, aes(x = Time, y = Hauteur, fill=Time)) +
geom_boxplot() +
ggtitle("Box Plot de la hauteur pour chaque période") +
xlab("Période") +
ylab("Hauteur") +
theme_classic()

```

Ensuite nous représentons les box-plots de la hauteur moyenne pour
chaque type d'engrais.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Box Plot de la Hauteur des plantes pour chaque modalité du facteur Fertilisation", fig.dim=c(4,2.5)}
ggplot(data = datas, aes(x = Fertilisation, y = Hauteur, fill=Fertilisation)) +
geom_boxplot() +
ggtitle("Box Plot de la Hauteur des plantes pour chaque modalité du facteur Fertilisation") +
xlab("Fertilisant") +
ylab("Hauteur") +
theme_classic()
```

\newpage

Box-plots de la hauteur moyenne pour les différentes variétés.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Box Plot de la Hauteur des plantes pour chaque type d'engrais", fig.dim=c(4,2.5)}
ggplot(data = datas, aes(x = Varietes, y = Hauteur, fill=Varietes)) +
geom_boxplot() +
ggtitle("Box Plot de la hauteur des plantes pour chaque modalité du facteur Variété") +
xlab("Variétés") +
ylab("Hauteur") +
theme_classic()
```

On va qu'il y a des valeurs abérrantes et que les moyennes suivant les
variétés sont presque proche. Enfin, nous représentons les box-plots
pour chaque modalité des diffrents facteurs.

```{r, fig.cap="Box Plot de la Hauteur des plantes pour chaque Variété",fig.align='center', fig.dim=c(4,2.5)}
ggplot(data = datas, aes(x = Fertilisation, y = Hauteur, color=Varietes)) +
geom_boxplot() +
ggtitle("Box Plot de la hauteur des plantes pour chaque modalité du facteur Variété") +
xlab("Fertilisation") +
ylab("Hauteur") +
theme_classic()
```

```{r, warning=FALSE, message=TRUE, fig.align='center', fig.cap="Box-plot de l'effet de la variétés pour chaque mesure-période",fig.dim=c(4,2.8)}
bxp <- ggboxplot(

  datas, x = "Fertilisation", y = "Hauteur",

  color = "Time",

  facet.by = "Varietes", short.panel.labs = FALSE

  )

bxp
```

```{r, warning=FALSE, message=TRUE, fig.align='center', fig.cap="Box-plot de l'effet des fertilisants  pour chaque mesure (période)",fig.dim=c(4,2.8)}
bxp <- ggboxplot(

  datas, x = "Varietes", y = "Hauteur",

  color = "Time",

  facet.by = "Fertilisation", short.panel.labs = FALSE

  )

bxp
```

\newpage

L'on constate la présence de valeurs abérrantes sur les box-plots
ci-dessus. Lesquelles peuvent biaiser l'interprétation des résultats.
Des transformations seraient donc appropriées ou la suppréssion de
celles-ci. Mais toutefois, nous pouvons d'abord essayer voir si
numériquement elles sont assez élevées. Ensuite conclure sur la décision
à prendre.

\textcolor{blue}{\textbf{Identifiaction des valeurs aberrantes}}

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.dim=c(4,2.5)}
outliers = identify_outliers(group_by(datas, Time), Hauteur)
kable(outliers, caption = "Tableau d'identification des valeurs aberrantes")
```

Nous avons bien des valeurs aberrantes dans notre jeu de données. Mais
elles sont pas nombreuses et tellement élévées. On peut faire un nuage
de poits des facteurs pour chaque hauteur des plantes.

\textcolor{blue}{\textbf{Pour les différents types d'engrais}}

```{r, fig.cap="Alignement de Hauteurs moyennes-cas du fertilisant", fig.dim=c(4,1.5), fig.align='center'}

ggplot(datas) +
 aes(x = Fertilisation, y = Hauteur, fill = Fertilisation) +
 geom_point() +
 scale_fill_hue(direction = 1) +
 theme_minimal()

```

\newpage

\textcolor{blue}{\textbf{Pour les différentes variétés}}

```{r, fig.cap="Alignement de Hauteurs moyennes-Cas de la variété", fig.dim=c(4,2.8)}
ggplot(datas) +
 aes(x = Varietes, y = Hauteur, fill = Varietes) +
 geom_point() +
 scale_fill_hue(direction = 1) +
 theme_minimal()
```

On peut dire que ces valeurs aberrantes ne sont pas tellement élevées.
Pour le voir on regarde juste les points les plus hauts sur chaque
graphique. En conclusion, ce n'est pas la peine de traiter les valeurs
aberrantes, sinon on risque modifier la structure des données.

\textcolor{blue}{\subsection{Hypothèses de base nécessaires à la modélisation}}

\textcolor{blue}{\subsubsection{Hypothèses de normalité}}

Elle est faite sur la variable cible pour chaque modalité du facteur
considéré suivant la période de mesure. L'objectif étant via celle-ci de
construire des tests pour une interprétation fiable. Commençons par
faire une observation graphique via un qqplot.

\textcolor{blue}{Hypothèse de normalité de la variable cible prise individuellement}

```{r}
shapiro.test(datas$Hauteur)
```

On constate que notre variable cible y n'est pas distribuée suivant une
loi normale car la p-value étant inférieure au seuil de $5\%$. Combinée
à la présence de valeurs manquantes, on peut voir s'il y a des
transformations sur nos données pouvant aux mieux nous aider.

\textcolor{blue}{Tansformation log-linéaire}

```{r}
datas$log_hauteur = log(datas$Hauteur)
kable(head(datas$log_hauteur, 5), caption = "Log de la hauteur pour les 5 primières lignes") 
```

```{r}
shapiro.test(datas$log_hauteur)
```

La conclusion reste la même. On ne peut donc utiliser une transformation
log-linéaire.

\textcolor{blue}{Tansformation Box-cox}

La transformation de Box-Cox peut être utilisée pour rendre les données
plus symétriques et plus conformes à une distribution normale. Cela peut
faciliter l'analyse statistique, en particulier lorsque des tests
statistiques qui supposent une distribution normale sont utilisés. Le
choix optimal de la valeur de lambda dépend de la distribution initiale
de la variable et peut être déterminé en utilisant une procédure de
recherche d'optimisation sur la fonction de vraisemblance de
l'échantillon ici notre jeu de donées.

```{r}
boxcox(datas$Hauteur ~ 1, lambda = seq(-2, 2, 0.01))
```

Notre paramètre optimal $\lambda$ est donc entre $]1,5;1,99[$. Prenons
$\lambda = 1,95$ on fait donc une transformation de la hauteur de la
forme :

$$datasHauteur_{bc} = (datasHauteur^{\lambda} - 1)/ \lambda$$

```{r}
lambda = 1.95
datas$Hauteur_bc = (datas$Hauteur^lambda - 1)/lambda
shapiro.test(datas$Hauteur_bc)
```

Ainsi, au seuil de $2\%$ nous avons l'hypothèse de normalité de la
distribution. Les données sont très robuste aux changement d'échelle.
Nous les utiliserons ainsi. Tout en considérant comme robuste les test
de type III et les métriques qui seront utilisées plus-tard.

\textcolor{blue}{Normalité croisée}

```{r, warning=FALSE, message=FALSE, fig.cap="QQplot : la droite d'Henry", fig.align='center', fig.dim=c(3.9, 3.7)}
ggqqplot(datas, "Hauteur", ggtheme = theme_bw()) +
  facet_grid(Varietes ~ Fertilisation, labeller = "label_both")
```

L'alignement de ces points sur la droite **(droite d'Henry)** montre que
l'hypothèse de normalité vérifée. Toutefois, elle semble moins plausible
pour le croisement entre les modalités An et Dg ; Ma et Dg ; Ca et Ds.
Nous allons conforter cela via un test statistique. Le classique test de
shapiro-wilk sera donc utilisé.

\newpage

\textcolor{blue}{\textbf{Test de normalité}}

```{r, echo=FALSE, warning=FALSE, message=FALSE}
normalite_croisee = datas |> 
  group_by(Varietes, Fertilisation) |> 
  shapiro_test(Hauteur)
kable(normalite_croisee, caption = "Normalité croisée des modalités des facteurs")
```

Ces résultats semblent confirmer ceux précédemment édictés. Ainsi nous
devons procéder à des transformations de type logarithmiques, box-cox,
etc. Mais cela peut modifier la structure des données. Aussi, cette
hypothèse n'est pas vérifiée pour 3 croisement sur 6. Aussi les
métriques seront effectuées pour l'Anova plus tard sont robustes. Donc
elles pourront palier à cela.

\textcolor{blue}{\subsubsection{Hypothèse de sphéricité}}

L'hypothèse de sphéricité est une hypothèses importante dans les
analyses de variance à mesures répétées. Elle concerne la structure de
la matrice de variance-covariance des différences entre les mesures
répétées de la variable dépendante (ou variable cible) pour chaque
combinaison de niveaux des facteurs.

Plus précisément, l'hypothèse de sphéricité stipule que la variance des
différences entre chaque paire de mesures répétées est la même pour
toutes les paires. Cela signifie que la covariance entre les différences
entre deux mesures répétées doit être identique pour toutes les paires
de mesures répétées.

Si cette hypothèse est respectée, les résultats d'une ANOVA à mesures
répétées peuvent être interprétés de manière fiable. Cependant, si elle
n'est pas respectée, cela peut entraîner des erreurs de type I (faux
positifs) ou des résultats erronés dans l'analyse statistique.

Il existe plusieurs tests pour évaluer l'hypothèse de sphéricité, tels
que le test de Mauchly ou le test de Huitfeldt-Gabriel. Si l'hypothèse
de sphéricité n'est pas respectée, des corrections peuvent être
appliquées, telles que l'utilisation de l'ajustement de
Greenhouse-Geisser ou de l'ajustement de Huynh-Feldt pour ajuster les
degrés de liberté et obtenir des p-values plus précises.

Elle sera automatiquement vérifiée lors du test d'analyse de la variance
via les fonctions **Anova_test** ou **aov_car** de Rstudio. Elle est
déja intégrée à l'intérieur de ces dernières.

\textcolor{blue}{\textbf{Test d'homogéneité de la variance}}

```{r}
leveneTest(Hauteur ~ Varietes * Fertilisation * Time, data = datas)
```

On a une p-valeur supérieure au seuil de $5\%$ donc on accepte
l'hypothèse d'homogéneité des variances.

\textcolor{blue}{\section{Modélisation, résultats et interprétation}}

Nous allons tout d'abord effectuer une analyse de la variance à un
facteur pour chaque facteur (variété et fertilisant) pour déterminer si
chaque facteur a un effet significatif sur la taille des plantes. Si
l'un ou l'autre des facteurs n'est pas significatif, cela signifie qu'il
n'y a pas de différence significative entre les modalités de ce facteur.

\textcolor{blue}{\subsection{Anova à un facteur à mesures repétées pour le facteur Variété}}

Nous postulons le modèle suivant au vue des hypothèses ci-dessus
vérifiées :

$$Y_{jk} = \mu + \beta_j + + \varepsilon_{jk}$$ Pour le cas d'espèce, on
peut utiliser la fonction aov qui nous fournit directement les
résultats. Les autres fonctions aboutissant à la même conclusion quant
au test de significativité.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
res.aov1 = aov(Hauteur ~ Varietes + Error(Repetition/(Varietes)), data = datas)
summary(res.aov1)
```

On constate donc que la p-value (0.146) est supérieur au seuil de $5\%$.
On a donc confiance à $95\%$ que le facteur **variété** n'est pas
signifiactif. cela signifie qu'il n'y a pas de différence significative
entre les modalités de ce facteur. Pour chaque modalité de ce facteur,
les effets sont les mêmes sur la hauteur des plantes pour chaque mesure.
La hauteur des plantes n'est pas forcément l'effet du type de variété.

\textcolor{blue}{\subsection{Anova à un facteur à mesures repétées pour le facteur Fertilisation}}

Soit le modèle ci-dessous
$$Y_{ik} = \mu + \alpha_i+ + \varepsilon_{ik}$$ On utilise également la
fonction aov :

```{r, echo=FALSE, warning=FALSE, message=FALSE}
res.aov2 = aov(Hauteur ~ Fertilisation+ Error(Repetition/(Fertilisation)), data = datas)
summary(res.aov2)
```

La p-value étant également supérieure au seuil, il n'y a donc pas de
différence significative entre les modalités du facteur fertilisation
sur la croissance des plantes. Pour chaque modalité de ce facteur, les
effets sont les mêmes sur la hauteur des plantes pour différentes
mesures.

\textcolor{blue}{\subsection{Analyse de la variance à deux facteurs à mesures repétées avec intéraction}}

Au regard des précédents résultats, on peut donc effectuer une ANOVA à
deux facteurs à mesures répétées afin de voir les effets principaux de
la variété et du fertilisant, ainsi que l'interaction entre les deux
facteurs. L'interaction est importante car elle indique si l'effet de la
variété sur la taille des plantes dépend du fertilisant utilisé (et vice
versa).

Soit le modèle suivant :

$$Y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha \beta)_{ij} + \varepsilon_{ijk}$$
Nous avons les degrés de libertés ci-dessous :

```{=tex}
\begin{table}[!h]
\centering
\caption{Degrés de liberté}
\includegraphics[width = 10cm]{t4.png}
\end{table}
```
Rappel :

Le tableau d'analyse de la variance se présente comme suit :

```{=tex}
\begin{table}[!h]
\centering
\caption{Tableau d'analyse de la variance-Rappel}
\includegraphics[width = 10cm]{t3.png}
\end{table}
```
\newpage

En faisant une application numérique, on obtient :

```{r, echo=FALSE, warning=FALSE, message=FALSE}

res.aov = aov_car(Hauteur ~ Fertilisation*Varietes + Error(Repetition/(Fertilisation*Varietes)), data = datas)

knitr::kable(nice(res.aov), caption = "Analyse de la variance")
```

Le tableau ci-dessus est celui de l'analyse de la variance pour les deux
facteurs et avec interaction entre les deux. Fort est de constater que
l'interaction entre les deux n'est pas significative, effectuer des
comparaisons post-hoc pour déterminer les différences significatives
entre les modalités des deux facteurs pour chaque niveau du facteur
restant n'est donc pas nécessaire. On peut dire en conclusion que
l'effet de la variété sur la taille des plantes ne dépend pas du
fertilisant utilisé et vice versa.

Comme mentionné dans les sections précédentes, l'hypothèse de sphéricité
sera automatiquement vérifiée lors du calcul du test ANOVA en utilisant
la fonction R anova_test() ou aov_car (ci-dessus). Le test de Mauchly
est utilisé en interne pour évaluer l'hypothèse de sphéricité. Aussi, la
correction de sphéricité de Greenhouse-Geisser est automatiquement
appliquée aux facteurs qui violent l'hypothèse de sphéricité.

```{r, echo=FALSE, warning=FALSE, message=FALSE}

summary(res.aov)

```

Mauchly Tests for Sphericity représente le test de sphéricité de Mauchly
qui est donc significatif. L'hypothèse de sphéricité est bien vérifiée.
Ensuite, nous avons la correction de Greenhouse-Geisser et les degrés de
libertés.

\textcolor{blue}{Validation des résultats}

\textcolor{blue}{Normalité des résidus}

```{r}
residus <- resid(res.aov)
shapiro.test(residus)
```

Au seuil de $1\%$ et de $2\%$, de $3%$ et de $4%$ les résidus suivent
une loi normale

\newpage

\textcolor{blue}{\section*{conclusion}}

La présente étude avait pour objectif d'étudier l'influence du type de
terreau et de la variété sur la croissance des plantes. Il en ressort
que quelque la soit la combianaison des facteurs : à un facteur, deux
facteurs avec ou sans intéraction, il y a absence d'effets de groupe des
modalités prises croisément pour les deux facteurs. Et prises
individuellement. En d'autres, termes elles ont les mêmes effets sur la
croissance des plantes. Comme susmentionné ci-haut : l'effet de la
variété sur la taille des plantes ne pas dépend du fertilisant utilisé
et vice versa. Certaines hypothèses étant violées pour un certain seuil,
il convient de pousser l'analyse plus loin pour conforter les résultats.
Par exemple en considérant de l'Anova non paramétrique.
